{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "import builtins\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2.service_account import Credentials\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
      "     -------------------------------------- 65.6/65.6 kB 878.7 kB/s eta 0:00:00\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\scrfl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.66.1)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\scrfl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.5.0->openai)\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\scrfl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.6 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.14.6-cp310-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\scrfl\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>4->openai) (0.4.4)\n",
      "Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
      "   ---------------------------------------- 225.4/225.4 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 85.5/85.5 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 75.9/75.9 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 76.9/76.9 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "   ---------------------------------------- 381.9/381.9 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.14.6-cp310-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 1.9/1.9 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: typing-extensions, sniffio, h11, exceptiongroup, distro, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.0.1\n",
      "    Uninstalling typing_extensions-4.0.1:\n",
      "      Successfully uninstalled typing_extensions-4.0.1\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.2.0 distro-1.9.0 exceptiongroup-1.2.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.6.1 pydantic-2.5.3 pydantic-core-2.14.6 sniffio-1.3.0 typing-extensions-4.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wprint(*args, width=70, **kwargs):\n",
    "    wrapper = textwrap.TextWrapper(width=width)\n",
    "    wrapped_args = [wrapper.fill(str(arg)) for arg in args]\n",
    "    builtins.print(*wrapped_args, **kwargs)\n",
    "\n",
    "\n",
    "def get_completion(message, agent, funcs, thread, client):\n",
    "    # Create new message in the thread\n",
    "    message_response = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=message\n",
    "    )\n",
    "\n",
    "\n",
    "    # Run the thread\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=agent.id,\n",
    "    )\n",
    "\n",
    "\n",
    "    while True:\n",
    "        # Wait until run completes\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "\n",
    "\n",
    "        if run.status in ['queued', 'in_progress']:\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "\n",
    "        if run.status == \"requires_action\":\n",
    "            tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "            tool_outputs = []\n",
    "            for tool_call in tool_calls:\n",
    "                print(f\"Debug: Calling function {tool_call.function.name}\", flush=True)\n",
    "\n",
    "\n",
    "                wprint(f'\\033[31mFunction: {tool_call.function.name}\\033[0m')\n",
    "                func = next((f for f in funcs if f.__name__ == tool_call.function.name), None)\n",
    "                if func:\n",
    "                    try:\n",
    "                        # Assuming arguments are parsed correctly\n",
    "                        func_instance = func(**eval(tool_call.function.arguments))  # Consider safer alternatives to eval\n",
    "                        output = func_instance.run()\n",
    "\n",
    "\n",
    "                        # Ensure output is a string\n",
    "                        if not isinstance(output, str):\n",
    "                            output = str(output)\n",
    "                    except Exception as e:\n",
    "                        output = f\"Error: {e}\"\n",
    "                else:\n",
    "                    output = \"Function not found\"\n",
    "                wprint(f\"\\033[33m{tool_call.function.name}: {output}\\033[0m\")\n",
    "                tool_outputs.append({\"tool_call_id\": tool_call.id, \"output\": output})\n",
    "\n",
    "\n",
    "            run = client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=tool_outputs\n",
    "            )\n",
    "        elif run.status == \"failed\":\n",
    "            raise Exception(f\"Run Failed. Error: {run.last_error}\")\n",
    "        else:\n",
    "            messages = client.beta.threads.messages.list(\n",
    "                thread_id=thread.id\n",
    "            )\n",
    "            latest_message = messages.data[0].content[0].text.value\n",
    "            return latest_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleanerAssistant :\n",
    "    openai_schema = {\n",
    "        \"name\": \"data_cleaner_and_uploader\",\n",
    "        \"description\": \"Cleans a dataframe and uploads it to a specified Google Sheet\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"dataframe_path\": {\"type\": \"string\", \"description\": \"Path to the dataframe file\"},\n",
    "                \"sheet_name\": {\"type\": \"string\", \"description\": \"Name of the Google Sheet to upload data\"}\n",
    "            },\n",
    "            \"required\": [\"dataframe_path\", \"sheet_name\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def __init__(self, dataframe_path, sheet_name) -> None:\n",
    "        self.dataframe_path = dataframe_path\n",
    "        self.sheet_name = sheet_name\n",
    "\n",
    "    def clean_dataframe(self, df):\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        df = df.convert_dtypes()\n",
    "\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def upload_sheet(self, df):\n",
    "        creds = Credentials.from_service_account_file()\n",
    "        client = gspread.authorize(creds)\n",
    "        sheet = client.open(self.sheet_name).sheet1\n",
    "        sheet.clear\n",
    "        sheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
    "    def run(self):\n",
    "        try:\n",
    "            df = pd.read_csv(self.dataframe_path)\n",
    "            clean_df = self.clean_dataframe(df)\n",
    "            self.upload_to_sheet(clean_df)\n",
    "            return \"Data cleaned and uploaded successfully.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner_and_uploader_tool = DataCleanerAssistant.openai_schema\n",
    "\n",
    "assistant_tools = [data_cleaner_and_uploader_tool] \n",
    "\n",
    "# Create the assistant with the specified tools\n",
    "data_assistant_ = client.beta.assistants.create(\n",
    "    name='Data Assistant',\n",
    "    instructions=\"Take in data frames and clean it and transform it into a google sheet.\",\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    tools=assistant_tools\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new thread for interaction\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Example user input\n",
    "user_input = \"Please clean the data in 'data.csv' and upload it to 'MySheet'\"\n",
    "message = get_completion(user_input, data_assistant, [DataCleanerAssistant], thread, client)\n",
    "print(message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
